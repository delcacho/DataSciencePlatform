{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import H2O Python library\n",
    "import h2o\n",
    "# View all the available H2O python functions\n",
    "#dir(h2o)\n",
    "\n",
    "# Parse Chicago Crime dataset into H2O\n",
    "column_type = ['numeric','string','string','enum','enum','enum','enum','enum','enum','enum','numeric','numeric','numeric','numeric','enum','numeric','numeric','numeric','enum','numeric','numeric','enum']\n",
    "f_crimes = h2o.import_file(path =\"https://raw.githubusercontent.com/h2oai/h2o-tutorials/master/tutorials/data/chicagoCrimes10k.csv\",col_types =column_type)\n",
    "\n",
    "print(f_crimes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_crimes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the distribution of IUCR column\n",
    "f_crimes[\"IUCR\"].table()\n",
    "\n",
    "# Look at distribution of Arrest column\n",
    "f_crimes[\"Arrest\"].table()\n",
    "\n",
    "# Modify column names to replace blank spaces with underscore\n",
    "col_names = list(map(lambda s: s.replace(' ', '_'), f_crimes.col_names))\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_crimes.set_names(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Refine date column \n",
    "def refine_date_col(data, col, pattern):\n",
    "    data[col]         = data[col].as_date(pattern)\n",
    "    data[\"Day\"]       = data[col].day()\n",
    "    data[\"Month\"]     = data[col].month()    # Since H2O indexes from 0\n",
    "    data[\"Year\"]      = data[col].year()\n",
    "    data[\"WeekNum\"]   = data[col].week()\n",
    "    data[\"WeekDay\"]   = data[col].dayOfWeek()\n",
    "    data[\"HourOfDay\"] = data[col].hour()\n",
    "    \n",
    "    # Create weekend and season cols\n",
    "    data[\"Weekend\"] = (data[\"WeekDay\"] == \"Sun\" or data[\"WeekDay\"] == \"Sat\").ifelse(1, 0)[0]\n",
    "    data[\"Season\"] = data[\"Month\"].cut([0, 2, 5, 7, 10, 12], [\"Winter\", \"Spring\", \"Summer\", \"Autumn\", \"Winter\"])\n",
    "    \n",
    "refine_date_col(f_crimes, \"Date\", \"%m/%d/%Y %I:%M:%S %p\")\n",
    "f_crimes = f_crimes.drop(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Census data into H2O\n",
    "f_census = h2o.import_file(\"https://raw.githubusercontent.com/h2oai/h2o-tutorials/master/tutorials/data/chicagoCensus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update column names in the table\n",
    "col_names = list(map(lambda s: s.strip().replace(' ', '_'), f_census.col_names))\n",
    "f_census.set_names(col_names)\n",
    "f_census = f_census[1:78,:]\n",
    "print(f_census.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Weather data into H2O\n",
    "f_weather = h2o.import_file(\"https://raw.githubusercontent.com/h2oai/h2o-tutorials/master/tutorials/data/chicagoAllWeather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_weather = f_weather[1:]\n",
    "print(f_weather.dim)\n",
    "#f_weather.summary()\n",
    "\n",
    "# Look at all the null entires in the Weather table\n",
    "f_weather[f_weather[\"meanTemp\"].isna()]\n",
    "\n",
    "f_weather\n",
    "\n",
    "# Copy data frames to Spark from H2O\n",
    "df_weather = hc.asSparkFrame(f_weather,)\n",
    "df_census = hc.asSparkFrame(f_census)\n",
    "df_crimes = hc.asSparkFrame(f_crimes)\n",
    "\n",
    "# Look at the weather data as parsed in Spark\n",
    "df_weather.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join columns from Crime, Census and Weather DataFrames in Spark\n",
    "sqlContext.sql(\"set spark.sql.caseSensitive=false\") \n",
    "## Register DataFrames as tables in SQL context\n",
    "sqlContext.registerDataFrameAsTable(df_weather, \"chicagoWeather\")\n",
    "sqlContext.registerDataFrameAsTable(df_census, \"chicagoCensus\")\n",
    "sqlContext.registerDataFrameAsTable(df_crimes, \"chicagoCrime\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimeWithWeather = sqlContext.sql(\"\"\"SELECT\n",
    "a.Year, a.Month, a.Day, a.WeekNum, a.HourOfDay, a.Weekend, a.Season, a.WeekDay,\n",
    "a.IUCR, a.Primary_Type, a.Location_Description, a.Community_Area, a.District,\n",
    "a.Arrest, a.Domestic, a.Beat, a.Ward, a.FBI_Code,\n",
    "b.minTemp, b.maxTemp, b.meanTemp,\n",
    "c.PERCENT_AGED_UNDER_18_OR_OVER_64, c.PER_CAPITA_INCOME, c.HARDSHIP_INDEX,\n",
    "c.PERCENT_OF_HOUSING_CROWDED, c.PERCENT_HOUSEHOLDS_BELOW_POVERTY,\n",
    "c.`PERCENT_AGED_16+_UNEMPLOYED`, c.`PERCENT_AGED_25+_WITHOUT_HIGH_SCHOOL_DIPLOMA`\n",
    "FROM chicagoCrime a\n",
    "JOIN chicagoWeather b\n",
    "ON a.Year = b.year AND a.Month = b.month AND a.Day = b.day\n",
    "JOIN chicagoCensus c\n",
    "ON a.Community_Area = c.Community_Area_Number\"\"\")\n",
    "\n",
    "# Print the crimeWithWeather data table from Spark\n",
    "crimeWithWeather.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy table from Spark to H2O\n",
    "crimeWithWeatherHF = hc.asH2OFrame(crimeWithWeather,h2oFrameName=\"crimeWithWeather\")\n",
    "\n",
    "crimeWithWeatherHF.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign column types to the CrimeWeatherHF data table in H2O\n",
    "crimeWithWeatherHF[\"Season\"]= crimeWithWeatherHF[\"Season\"].asfactor()\n",
    "crimeWithWeatherHF[\"WeekDay\"]= crimeWithWeatherHF[\"WeekDay\"].asfactor()\n",
    "crimeWithWeatherHF[\"IUCR\"]= crimeWithWeatherHF[\"IUCR\"].asfactor()\n",
    "crimeWithWeatherHF[\"Primary_Type\"]= crimeWithWeatherHF[\"Primary_Type\"].asfactor()\n",
    "crimeWithWeatherHF[\"Location_Description\"]= crimeWithWeatherHF[\"Location_Description\"].asfactor()\n",
    "crimeWithWeatherHF[\"Arrest\"]= crimeWithWeatherHF[\"Arrest\"].asfactor()\n",
    "crimeWithWeatherHF[\"Domestic\"]= crimeWithWeatherHF[\"Domestic\"].asfactor()\n",
    "crimeWithWeatherHF[\"FBI_Code\"]= crimeWithWeatherHF[\"FBI_Code\"].asfactor()\n",
    "crimeWithWeatherHF[\"Season\"]= crimeWithWeatherHF[\"Season\"].asfactor()\n",
    "\n",
    "crimeWithWeatherHF.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split final H2O data table into train test and validation sets\n",
    "ratios = [0.6,0.2]\n",
    "frs = crimeWithWeatherHF.split_frame(ratios,seed=12345)\n",
    "train = frs[0]\n",
    "train.frame_id = \"Train\"\n",
    "valid = frs[2]\n",
    "valid.frame_id = \"Validation\"\n",
    "test = frs[1]\n",
    "test.frame_id = \"Test\"\n",
    "\n",
    "# Import Model Builders from H2O Python\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Preditors\n",
    "predictors = crimeWithWeatherHF.names[:]\n",
    "response = \"Arrest\"\n",
    "predictors.remove(response)\n",
    "\n",
    "#Simple GBM model - Predict Arrest\n",
    "model_gbm = H2OGradientBoostingEstimator(ntrees         =50,\n",
    "                                        max_depth      =6,\n",
    "                                        learn_rate     =0.1, \n",
    "                                        #nfolds         =2,\n",
    "                                        distribution   =\"bernoulli\")\n",
    "\n",
    "model_gbm.train(x               =predictors,\n",
    "               y               =\"Arrest\",\n",
    "               training_frame  =train,\n",
    "               validation_frame=valid\n",
    "               )\n",
    "\n",
    "# Simple Deep Learning - Predict Arrest\n",
    "model_dl = H2ODeepLearningEstimator(variable_importances=True,\n",
    "                                   loss                =\"Automatic\")\n",
    "\n",
    "model_dl.train(x                =predictors,\n",
    "              y                =\"Arrest\",\n",
    "              training_frame  =train,\n",
    "              validation_frame=valid)\n",
    "\n",
    "# Print confusion matrices for the train and validation set\n",
    "print(model_gbm.confusion_matrix(train = True))\n",
    "print(model_gbm.confusion_matrix(valid = True))\n",
    "\n",
    "print(model_gbm.auc(train=True))\n",
    "print(model_gbm.auc(valid=True))\n",
    "model_gbm.plot(metric=\"auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySparkling + Sparkling Water",
   "language": "python",
   "name": "pysparkling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
